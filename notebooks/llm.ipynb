{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UtkarshVerma\\Desktop\\ct_miner_ml_os\\venv_ct_miner_ml_os\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "llm = CTransformers(model='../model/llama-2-7b-chat.ggmlv3.q8_0.bin', \n",
    "                    model_type='llama',\n",
    "                    config={'max_new_tokens': 100, \n",
    "                            'temperature': 0.01\n",
    "                            }\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25-year-old software engineer who has been working at a startup for the past three years. He is passionate about technology and loves to stay up to date with the latest trends in the industry. In his free time, he enjoys playing video games and watching movies. Despite his busy schedule, Anirudh always makes time for his friends and family, as he believes that a strong support system is essential for personal growth and happiness.\n",
      "\n",
      "Anir\n"
     ]
    }
   ],
   "source": [
    "response = llm(\"complete the introduction: anirudh is a\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import CTransformers\n",
    "\n",
    "class Llama2:\n",
    "    def __init__(self):\n",
    "        self.llama2 = CTransformers(model='../model/llama-2-7b-chat.ggmlv3.q8_0.bin', \n",
    "                    model_type='llama',\n",
    "                    # n_ctx=4096,\n",
    "                    config={'max_new_tokens': 100, \n",
    "                            'temperature': 0.01,\n",
    "                            'context_length': 4096\n",
    "                            }\n",
    "                    )\n",
    "        \n",
    "    def fetch_response(self, conversation_id, prompt):\n",
    "        print(f\"fetching llm response for conversation_id {conversation_id} and prompt\", \"\\n\\n\", f\"{prompt}\") # print\n",
    "        response = self.llama2(prompt)\n",
    "        print(\"llm response \\n\\n\", f\"{response}\") # print\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama = Llama2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Given the following conversation and a New Question question, rephrase the New Question question to be a standalone question only if it alignes with the below mentioned Important Instructions.\n",
    "IMPORTANT INSTRUCTIONS-\n",
    "1. If New Question seems to be a follow-up question of the Old Question strictly only then rephrase the New Question.\n",
    "2. If New Question does not seems to be a follow-up question of the Old Question then strictly do not rephrase the New Question and strictly just respond \"Not a follow-up question\".\n",
    "3. Responses will strictly follow the Response format provided above.\n",
    "4. You will never provide answers to the New Question.\n",
    "5. Carefully provide the rephrased question by not missing any relevant details in the given conversation that are needed to answer the New Question.\n",
    "6. Do not refer by using terms such as 'previous answer' or 'mentioned earlier' in the rephrased question, add all the necessary information needed in the rephrased question itself.\n",
    "7. Response format:\n",
    "REPHRASED QUERY: rephrased query\n",
    "8. Refer the below few-shot conversation examples strictly just to understand how to formulate respond, but strictly never use these examples directly as response:\n",
    "# Few-shot example 1-\n",
    "    Old Question: [INST] What are debt funds? [/INST]\n",
    "    Old Answer: It is an investment option.\n",
    "    New Question: [INST] Hey! [/INST]\n",
    "    Rephrased Question: Not a follow-up question\n",
    "# Few-shot example 2-\n",
    "    Old Question: [INST] What are debt funds? [/INST]\n",
    "    Old Answer: It is an investment option.\n",
    "    New Question: [INST] What are it's types? [/INST]\n",
    "    Rephrased Question: What are the types of debt funds?\"\n",
    "9. Understand all the above instructions very clearly and strictly based on above instructions comprehend the below conversation and formulate response for below mentioned New Question\n",
    "\n",
    "Old Question: [INST] what is the age of utkarsh [/INST]\n",
    "Old Answer: utkarsh is 23 years old\n",
    "New Question: [INST] hey [/INST]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching llm response for conversation_id 9997580440 and prompt \n",
      "\n",
      " Given the following conversation and a New Question question, rephrase the New Question question to be a standalone question only if it alignes with the below mentioned Important Instructions.\n",
      "IMPORTANT INSTRUCTIONS-\n",
      "1. If New Question seems to be a follow-up question of the Old Question strictly only then rephrase the New Question.\n",
      "2. If New Question does not seems to be a follow-up question of the Old Question then strictly do not rephrase the New Question and strictly just respond \"Not a follow-up question\".\n",
      "3. Responses will strictly follow the Response format provided above.\n",
      "4. You will never provide answers to the New Question.\n",
      "5. Carefully provide the rephrased question by not missing any relevant details in the given conversation that are needed to answer the New Question.\n",
      "6. Do not refer by using terms such as 'previous answer' or 'mentioned earlier' in the rephrased question, add all the necessary information needed in the rephrased question itself.\n",
      "7. Response format:\n",
      "REPHRASED QUERY: rephrased query\n",
      "8. Refer the below few-shot conversation examples strictly just to understand how to formulate respond, but strictly never use these examples directly as response:\n",
      "# Few-shot example 1-\n",
      "    Old Question: [INST] What are debt funds? [/INST]\n",
      "    Old Answer: It is an investment option.\n",
      "    New Question: [INST] Hey! [/INST]\n",
      "    Rephrased Question: Not a follow-up question\n",
      "# Few-shot example 2-\n",
      "    Old Question: [INST] What are debt funds? [/INST]\n",
      "    Old Answer: It is an investment option.\n",
      "    New Question: [INST] What are it's types? [/INST]\n",
      "    Rephrased Question: What are the types of debt funds?\"\n",
      "9. Understand all the above instructions very clearly and strictly based on above instructions comprehend the below conversation and formulate response for below mentioned New Question\n",
      "\n",
      "Old Question: [INST] what is the age of utkarsh [/INST]\n",
      "Old Answer: utkarsh is 23 years old\n",
      "New Question: [INST] hey [/INST]\n",
      "llm response \n",
      "\n",
      " \n",
      "Rephrased Question: Not a follow-up question\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nRephrased Question: Not a follow-up question'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama.fetch_response(\"9997580440\",prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ct_miner_ml_os",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
